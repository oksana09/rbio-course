---
title: "Homework_decision_tree"
author: "Оксана Владимировна Айзсилниекс"
date: "22 05 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, warning=FALSE,message=FALSE}
library(randomForest)
library(ggplot2)
library(dplyr)
library(rpart)
```

#Восстановление возраста по данным метелирования
Данные для этой данной домашней работы мы возьмем из статьи “A novel strategy for forensic age prediction by DNA methylation and support vector regression model”, Cheng Xu et al, Scientific reports 2015. (Статья будет в архиве), где авторы попытались построить предсказатель возраста человека по данным метилирования отдельных CpG sites. Данные будут выглядеть следующим образом:

```{r echo=FALSE, warning=FALSE, cashe = T}
ages <- read.table("ages.tsv", sep="\t", header=1)
head(ages)
```

В табличке “ages.tsv” лежат идентификаторы доноров, возраст, и название array, которым это всё добро сделали.

```{r echo=FALSE, warning=FALSE, cashe = T}
methylation <- read.table("methylation.tsv", sep="\t", header=1, row.names = 1, na.strings = "NA")
print(methylation[1:5, 1:5])
```

В табличке “methylation.tsv” лежат данные про CpG сайты, где эти сайты на геноме находятся, а что самое главное, доля метилирования каждого сайта у наших доноров. Однако в этой табличке также есть NA-значения, авторы статьи утверждают, что это означает “no methylation detected”, и считают их за 0 (вам я их тоже предлагаю считать за 0).

Чтобы NA заменить на 0, попробуем проделать простой инструментальный такт.

```{r echo=FALSE, warning=FALSE, cashe = T}
methylation[is.na(methylation)] <- 0

# Ask an array the question

any(is.na(methylation))
```

#Предподготовка данных

Вообще сайтов метилирования там какое-то не очень большое количество (95 сайтов), однако часть из них абсолютно не скоррелирована с возрастом, и наверняка вряд ли поможет нам в решении задачи регрессии. Хочется проделать примерно то же, что проделали авторы статьи – сделать ручками очень простой feature selection. Давайте оставим только те, сайты метилирования, которые наиболее скоррелированы с возрастом.

Переподготовка:

1. Для каждого сайта метилирования, посчитать корреляцию между долей метилирования этого сайта в доноре и возрасте донора.
2. Оставить только 10 самых скоррелированных сайтов. Под самыми скоррелированными мы понимаем абсолютное значение корреляции.

```{r echo=FALSE, warning=FALSE, cashe = T}
table_methylation <- t(methylation[,4:ncol(methylation)])

table_methylation_age <- cbind(age = ages$Age, t(methylation[,4:ncol(methylation)]))

table_methylation_age <- as.data.frame(table_methylation_age)

correlation_matrix <- apply(table_methylation, 2, function(x) cor(as.numeric(x), table_methylation_age$age))

upper_cors <- sort(order(abs(correlation_matrix), decreasing = TRUE)[1:10])

upper_cors_methylation <- methylation[upper_cors,]

upper_cors_methylation <- upper_cors_methylation[,-c(1,2,3)]

#View(upper_cors_methylation)

#for_further_work <- as.data.frame(cbind(upper_cors_methylation,age=ages$Age))
#rownames(for_further_work) <- ages$Sample
```

Разделение выборок на тренирующую и валидирующую.

```{r echo=FALSE, warning=FALSE, cashe = T}
# здесь делаем так же, как и в занятии

set.seed(345)

training <- sample(1:50, 40)
training <- sort(training)
validation <- sort((1:50)[-training])

train_me <- as.data.frame(t(upper_cors_methylation[, training]))

valid_me <- as.data.frame(t(upper_cors_methylation[, validation]))

# check this

dim(train_me)
dim(valid_me)

aim_ages_sample_train <- ages$Sample[ages$Sample %in% rownames(train_me)]
aim_ages_sample_valid <- ages$Sample[ages$Sample %in% rownames(valid_me)]

train_response <- ages$Age[which(ages$Sample %in% aim_ages_sample_train)]
valid_response <- ages$Age[which(ages$Sample %in% aim_ages_sample_valid)]
```

### Wrapper_function, that was born out of my feverish mind

```{r echo=FALSE, warning=FALSE, cashe = T}
# Следуя предложенному шаблону функции

#' randomForest wrapper and error estimator
#'
#' @param train.data data.frame, training dataset
#' @param train.response numeric vector, values of dependent variables in training dataset
#' @param test.data data.frame, testing (validation) dataset
#' @param test.response numeric vector, values of dependent variables in testing dataset
#' @param runs.number numeric (integer), how many times we should run random forest
#' @param ... parameters that are passes to randomForest function, like
#'        ntree, mtry, nodesize, replace, sampsize
#'
#' @return numeric vector with two values, 
#'      first is mean of RMSE values on training data
#'      second is mean of RMSE values on testing data
#' @export
#'
#' @examples
wrapper_function <- function(train.data, train.response,
                    test.data, test.response, 
                    runs.number=50, ...) {
  # put your code inside
  N <- seq(1, runs.number)
  
  fit_random_forest <- lapply(N, function(x) randomForest(train.response ~ .,   data=train.data, ...))
  
  RMSE_for_train <- lapply(fit_random_forest, function(x) sqrt( sum((predict(x,train.data) - train.response)^2) / length(train.response)))
  
  RMSE_for_valid <- lapply(fit_random_forest, function(x) sqrt( sum((predict(x,test.data) - test.response)^2) / length(test.response)))

  m_RMSE_for_train <- mean(unlist(sapply(RMSE_for_train[1:length(RMSE_for_train)], '['))) 

  m_RMSE_for_valid <- mean(unlist(sapply(RMSE_for_valid[1:length(RMSE_for_valid)], '['))) 
    
  return(c(m_RMSE_for_train, m_RMSE_for_valid))
}

get_some <- wrapper_function(train_me, train_response, valid_me, valid_response)

# get_some values

get_some

```

###Оптимизация обучения

Параметры случайного леса Мы будем оптимизировать наш случайный лес по нескольким параметрам (эти параметры, являются аргументами функции randomForest). Напомню для сводки, что пускай NN – количество объектов в тренировочном датасете, MM – количество features в нашем датасете.

    ntree – количество деревьев в случайном лесе, по умолчанию 500

    replace – когда делается bagging (bootstrapping) нашего случайного леса, должны мы это делать с возвращением, или нет? По умолчанию, мы делает bagging с возвращением.

    sampsize – когда делается bagging (bootstrapping) нашего случайного леса, сколько мы должны взять объектов из тренировочного датасета? По умолчанию, если replace==TRUE мы берем все NN объектов, а если FALSE, то 23N23N

    nodesize – минимальный размер (по количеству объектов) для листовых вершин, значение по умолчанию – 5

    mtry – количество признаков, которое случайно выбирается при каждом разбиении (это также называется feature bagging)

Таким образом, если бы мы хотели, чтобы в нашем лесу, все деревья были переобучены, мы бы запустили это как-нибудь в духе:

###Займемся оптимизацией количества деревьев

у меня получается какая-то ерунда

```{r echo=FALSE, warning=FALSE, cashe=TRUE}

##NTREE. Мне кажется, что с какого-то момента ничего не должно меняться и можно брать с бОльшим шагом. Попробую 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024. Экспериментов в 20 раз меньше, чем если брать 200 чисел (от 1 до 1000), а результат, возможно, будет не хуже.

vector_ntree <- c(1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024)

output <- sapply(vector_ntree, function(t) wrapper_function(train_me, train_response, valid_me, valid_response,runs.number = 100, ntree=t))
general_df <- rbind(data.frame(trees=vector_ntree, SSE=output[1,], dataset="Train"),data.frame(trees=vector_ntree, SSE=output[2,], dataset="Validation"))

plotting_this <- ggplot(data=general_df, aes(x=trees, y=SSE, color=dataset)) +
    geom_point(size=3) + 
    geom_line(size=2) + ggtitle("SSE Plot Trees") + theme_bw()
```

