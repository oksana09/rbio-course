---
title: "Homework_decision_tree"
author: "Оксана Владимировна Айзсилниекс"
date: "22 05 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, warning=FALSE,message=FALSE}
library(randomForest)
library(ggplot2)
library(dplyr)
library(rpart)
```

#Восстановление возраста по данным метилирования
Данные для этой данной домашней работы мы возьмем из статьи “A novel strategy for forensic age prediction by DNA methylation and support vector regression model”, Cheng Xu et al, Scientific reports 2015. (Статья будет в архиве), где авторы попытались построить предсказатель возраста человека по данным метилирования отдельных CpG sites. Данные будут выглядеть следующим образом:

```{r echo=FALSE, warning=FALSE, cashe = T}
ages <- read.table("ages.tsv", sep="\t", header=1)
head(ages)
```

В табличке “ages.tsv” лежат идентификаторы доноров, возраст, и название array, которым это всё добро сделали.

```{r echo=FALSE, warning=FALSE, cashe = T}
methylation <- read.table("methylation.tsv", sep="\t", header=1, row.names = 1, na.strings = "NA")
print(methylation[1:5, 1:5])
typeof(methylation) 
```

В табличке “methylation.tsv” лежат данные про CpG сайты, где эти сайты на геноме находятся, а что самое главное, доля метилирования каждого сайта у наших доноров. Однако в этой табличке также есть NA-значения, авторы статьи утверждают, что это означает “no methylation detected”, и считают их за 0 (вам я их тоже предлагаю считать за 0).

Чтобы NA заменить на 0, попробуем проделать простой инструментальный такт.

```{r echo=FALSE, warning=FALSE, cashe = T}
methylation[is.na(methylation)] <- 0

# Ask an array the question

any(is.na(methylation))
```

#Предподготовка данных

Вообще сайтов метилирования там какое-то не очень большое количество (95 сайтов), однако часть из них абсолютно не скоррелирована с возрастом, и наверняка вряд ли поможет нам в решении задачи регрессии. Хочется проделать примерно то же, что проделали авторы статьи – сделать ручками очень простой feature selection. Давайте оставим только те, сайты метилирования, которые наиболее скоррелированы с возрастом.

Переподготовка:

1. Для каждого сайта метилирования, посчитать корреляцию между долей метилирования этого сайта в доноре и возрасте донора.
2. Оставить только 10 самых скоррелированных сайтов. Под самыми скоррелированными мы понимаем абсолютное значение корреляции.

```{r echo=FALSE, warning=FALSE, cashe = T}
table_methylation <- t(methylation[,4:ncol(methylation)])

table_methylation_age <- cbind(age = ages$Age, t(methylation[,4:ncol(methylation)]))

table_methylation_age <- as.data.frame(table_methylation_age)

correlation_matrix <- apply(table_methylation, 2, function(x) cor(as.numeric(x), table_methylation_age$age))

upper_cors <- sort(order(abs(correlation_matrix), decreasing = TRUE)[1:10])

upper_cors_methylation <- methylation[upper_cors,]

upper_cors_methylation <- upper_cors_methylation[,-c(1,2,3)]

#View(upper_cors_methylation)

upper_cors_methylation_t <- t(upper_cors_methylation)

for_further_work <- as.data.frame(cbind(age=ages$Age, upper_cors_methylation_t))

response_age <- for_further_work$age

```

Разделение выборок на тренирующую и валидирующую.

```{r echo=FALSE, warning=FALSE, cashe = T}
# здесь делаем так же, как и в занятии

set.seed(31)

training <- sample(1:50, 40)
training <- sort(training)
validation <- sort((1:50)[-training])

train_me <- as.data.frame(t(upper_cors_methylation[, training]))

valid_me <- as.data.frame(t(upper_cors_methylation[, validation]))

# check this

dim(train_me)
dim(valid_me)

aim_ages_sample_train <- ages$Sample[ages$Sample %in% rownames(train_me)]
aim_ages_sample_valid <- ages$Sample[ages$Sample %in% rownames(valid_me)]

train_response <- ages$Age[which(ages$Sample %in% aim_ages_sample_train)]
valid_response <- ages$Age[which(ages$Sample %in% aim_ages_sample_valid)]
```

### Wrapper_function, that was born out of my feverish mind

```{r echo=FALSE, warning=FALSE, cashe = T}
# Следуя предложенному шаблону функции

#' randomForest wrapper and error estimator
#'
#' @param train.data data.frame, training dataset
#' @param train.response numeric vector, values of dependent variables in training dataset
#' @param test.data data.frame, testing (validation) dataset
#' @param test.response numeric vector, values of dependent variables in testing dataset
#' @param runs.number numeric (integer), how many times we should run random forest
#' @param ... parameters that are passes to randomForest function, like
#'        ntree, mtry, nodesize, replace, sampsize
#'
#' @return numeric vector with two values, 
#'      first is mean of RMSE values on training data
#'      second is mean of RMSE values on testing data
#' @export
#'
#' @examples
wrapper_function <- function(train.data, train.response,
                    test.data, test.response, 
                    runs.number=50, ...) {
  # put your code inside
  N <- seq(1, runs.number)
  
  fit_random_forest <- lapply(N, function(x) randomForest(train.response ~ .,   data=train.data, ...))
  
  RMSE_for_train <- lapply(fit_random_forest, function(x) sqrt( sum((predict(x,train.data) - train.response)^2) / length(train.response)))
  
  RMSE_for_valid <- lapply(fit_random_forest, function(x) sqrt( sum((predict(x,test.data) - test.response)^2) / length(test.response)))

  m_RMSE_for_train <- mean(unlist(sapply(RMSE_for_train[1:length(RMSE_for_train)], '['))) 

  m_RMSE_for_valid <- mean(unlist(sapply(RMSE_for_valid[1:length(RMSE_for_valid)], '['))) 
    
  return(c(m_RMSE_for_train, m_RMSE_for_valid))
}

get_some <- wrapper_function(train_me, train_response, valid_me, valid_response)

# get_some values

get_some

```

###Оптимизация обучения

Параметры случайного леса Мы будем оптимизировать наш случайный лес по нескольким параметрам (эти параметры, являются аргументами функции randomForest). Напомню для сводки, что пускай NN – количество объектов в тренировочном датасете, MM – количество features в нашем датасете.

    ntree – количество деревьев в случайном лесе, по умолчанию 500

    replace – когда делается bagging (bootstrapping) нашего случайного леса, должны мы это делать с возвращением, или нет? По умолчанию, мы делает bagging с возвращением.

    sampsize – когда делается bagging (bootstrapping) нашего случайного леса, сколько мы должны взять объектов из тренировочного датасета? По умолчанию, если replace==TRUE мы берем все NN объектов, а если FALSE, то 23N23N

    nodesize – минимальный размер (по количеству объектов) для листовых вершин, значение по умолчанию – 5

    mtry – количество признаков, которое случайно выбирается при каждом разбиении (это также называется feature bagging)

Таким образом, если бы мы хотели, чтобы в нашем лесу, все деревья были переобучены, мы бы запустили это как-нибудь в духе:

###Займемся оптимизацией количества деревьев

##NTREE

От нас требуется построить график зависимости ошибок от параметра ntree. Ты предлагаешь перебрать ntree в интервале seq(1, 1000, 5), но можно перебрать и более удобные для нас значения: хочется лишь, чтобы начальное значение было достаточно маленьким, а конечное – достаточно большим.

Если всё идет хорошо, то вне зависимости от остальных параметров, которые определяют построение деревьев внутри случайного леса, начиная с какого-то момента, количество деревьев не влияет на результат ни в худшую, ни в лучшую сторону. Необходимо зафиксировать это количество деревьев, и использовать это число до конца выполнения домашней работы.

```{r echo=FALSE, warning=FALSE, cashe=TRUE}

##NTREE. Мне кажется, что с какого-то момента ничего не должно меняться и можно брать с бОльшим шагом. Попробую 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024. Экспериментов в 20 раз меньше, чем если брать 200 чисел (от 1 до 1000), а результат, возможно, будет не хуже.

vector_ntree <- c(1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024)

output <- sapply(vector_ntree, function(t) wrapper_function(train_me, train_response, valid_me, valid_response,runs.number = 100, ntree=t))
general_df <- rbind(data.frame(trees=vector_ntree, SSE=output[1,], dataset="Train"),data.frame(trees=vector_ntree, SSE=output[2,], dataset="Validation"))

plotting_this <- ggplot(data=general_df, aes(x=trees, y=SSE, color=dataset)) +
    geom_point(size=3) + 
    geom_line(size=2) + ggtitle("SSE Plot Trees") + theme_bw()

# Примерно с количества деревьев, равному 100, значение SSE не меняется. По всей видимости, можно зафикисировать это число.

plotting_this

ntree <- 110

```

##REPLACE and SAMPSIZE

В этой части задания ты хочешь, чтобы мы зафиксировали значения параметров ntree (из прошлого пункта и оно равно 110), mtry=10 (поскольку мы хотим, чтобы когда мы строим деревья, всем правилам были доступны все features), и nodesize=1 (поскольку мы хотим, чтобы в листовых вершинах оставалось по одному значению).

Ты хочешь, чтобы мы для этих “легко переобучаемых деревьев” оценили эффект переобучения в зависимости от параметров replace и sampsize.

график зависимости ошибки от sampsize (1:40) при replace=F
график зависимости ошибки от sampsize (1:40) при replace=T

Посмотрев на эти графики, мне необходимо описать, какая из этих моделей переобучается эффективнее. Это даст мне возможность зафиксировать значения replace и sampsize, для наименее переобученной модели, и использовать эти значения до конца выполнения домашней работы.

```{r echo=FALSE, warning=FALSE, cashe=TRUE}

vector_nsamp <- seq(1, 40, 1)

output_for_nsamp_true <- sapply(vector_nsamp, function(x) wrapper_function(train_me, train_response, valid_me, valid_response,runs.number = 100, ntree=ntree, nodesize=1, mtry=10, replace=T, sampsize=x))

nsamp_df_true <- rbind(data.frame(samples=vector_nsamp, SSE=output_for_nsamp_true[1,], dataset="Train"),data.frame(samples=vector_nsamp, SSE=output_for_nsamp_true[2,], dataset="Validation"))

output_for_nsamp_false <- sapply(vector_nsamp, function(x) wrapper_function(train_me, train_response, valid_me, valid_response,runs.number = 100, ntree=ntree, nodesize=1, mtry=10, replace=F, sampsize=x))

nsamp_df_false <- rbind(data.frame(samples=vector_nsamp, SSE=output_for_nsamp_false[1,], dataset="Train"),data.frame(samples=vector_nsamp, SSE=output_for_nsamp_false[2,], dataset="Validation"))

plotting_this_nsamp_true <- ggplot(data=nsamp_df_true, aes(x=samples, y=SSE, color=dataset)) + geom_point(size=3) + geom_line(size=2) +
                            ggtitle("SSE Plot Samplesize True") + theme_bw()

plotting_this_nsamp_false <- ggplot(data=nsamp_df_false, aes(x=samples, y=SSE, color=dataset)) + geom_point(size=3) + geom_line(size=2) +
                            ggtitle("SSE Plot Samplesize False") + theme_bw()

plotting_this_nsamp_true
plotting_this_nsamp_false

# глядя на графики, я могу сказать, что при replace=F минимальное значение SSE при количестве образцов (samples), равном 40. При replace=T значение SSE будто бы практически не меняется. Зафиксируем результаты?

replace <- TRUE
nsamp <- 40
```

##NODESIZE

В этой части задания ты хочешь, чтобы мы зафиксировали значения параметров ntree (из первого пункта и оно равно 110), mtry=10 (поскольку мы хотим, чтобы когда мы строим деревья, всем правилам были доступны все features), replace и sampsize (взять получившийся на предыдущем этапе результат).

Необходимо построить график зависимости ошибки от nodesize (1:40).

Нужно понять, а есть ли на этом графике переобучение?

Ты предлагаешь нам определить оптимальное значение nodesizе, зафиксировать его и использовать это значение до конца выполнения домашней работы.

Необходимо обратить внимание на то, что здесь стоит смотреть на график “справа налево”, так как при большом nodesize мы считаем decision tree недообученными, а при малом – переобученными.

```{r echo=FALSE, warning=FALSE, cashe=TRUE}
vector_nnode <-  seq(1, 40, 1)

output_nnodes <- sapply(vector_nsamp, function(x) wrapper_function(train_me, train_response, valid_me, valid_response,runs.number = 100, ntree=ntree,  mtry=10, replace=replace, sampsize=nsamp, nodesize=x))

nnodes_df <- rbind(data.frame(nodes=vector_nnode, SSE=output_nnodes[1,], dataset="Train"),data.frame(nodes=vector_nnode, SSE=output_nnodes[2,], dataset="Validation"))

plotting_this_nnodes <- ggplot(data=nnodes_df, aes(x=nodes, y=SSE, color=dataset)) + geom_point(size=3) + geom_line(size=2)+
                        ggtitle("SSE Plot Nodes") + theme_bw()

plotting_this_nnodes

nodesize <- 1

```

##MTRY

В этой части задания ты хочешь, чтобы мы зафиксировали значения параметров ntree, replace и sampsize, nodesize из предыдущих пунктов, а затем построили график зависимости ошибки от mtry (1:10).

Надо определить оптимальное значение mtry, зафиксировать его и использовать это значение до конца выполнения домашней работы.


```{r echo=FALSE, warning=FALSE, cashe=TRUE}
vector_nmtry <- seq(1, 10, 1)

output_nmtry <- sapply(vector_nmtry, function(x) wrapper_function(train_me, train_response, valid_me, valid_response, runs.number = 100, ntree=ntree, replace=replace, sampsize=nsamp, nodesize=nodesize, mtry=x))

mtry_df <- rbind(data.frame(mtry=vector_nmtry, SSE=output_nmtry[1,],dataset="Train"),
                 data.frame(mtry=vector_nmtry, SSE=output_nmtry[2,], dataset="Validation"))

plotting_this_mtry <- ggplot(data=mtry_df, aes(x=mtry, y=SSE, color=dataset)) + geom_point(size=3) + geom_line(size=2)+ggtitle("SSE Plot Mtry") + theme_bw()

plotting_this_mtry

nmtry <- 2

```

##CROSS VALIDATION

Теперь, после того как мы выбрали значения всех параметров для нашего случайного леса, необходимо выполнить кросс-валидацию. Кросс-валидация – это процесс разбиения датасета на части, и использование по очереди каждой части в качестве тестирующей выборки, а оставшегося – в качестве тренирующей. После этого считается среднее значение ошибки по всем частям, и это выдается как результат.

(Так, ты показываешь нам, как сделать кросс-валидацию на randomForest со значениями по умолчанию: датасет разбивается на 5 частей по 10 человек в каждой части, затем эти части используются по очереди в качестве тестирующих выборок, а оставшееся, - как обучающая. Затем считается ошибка для каждого разбиения и после этого - средняя ошибка).

Подставим в randomForest свои параметры, и посмотрим, как хорошо работает наш random forest по сравнению со случайным лесом по умолчанию.

```{r}
# our data, matrix 50 donors by 10 methylation sites
dim(for_further_work)
```

```{r}
# age of all donors
head(response_age)
```

```{r}
set.seed(1)

# splitting our dataset into 5 equal parts
cross.validation <- matrix(sample(1:50, 50), nrow=5, ncol=10)
cross.validation
```

С параметрами по умолчанию.

```{r}
cross.results <- apply(cross.validation, 1, function(test.sample){
  # using each part as testing dataset
  # using rest of the dataset as training dataset
  train.sample <- (1:50)[-test.sample]
  train.data <- for_further_work[train.sample, ]
  train.response <- response_age[train.sample]
  test.data <- for_further_work[test.sample, ]
  test.response <- response_age[test.sample]
  
  # calculating RMSE for every part and default random forest
  return(wrapper_function(train.data, train.response, test.data, test.response, 100))
})

print(cross.results)
print(rowMeans(cross.results))
```

С подобранными мою в этой работе параметрами.

```{r}
cross.results_with_params <- apply(cross.validation, 1, function(test.sample){
  # using each part as testing dataset
  # using rest of the dataset as training dataset
  train.sample <- (1:50)[-test.sample]
  train.data <- for_further_work[train.sample, ]
  train.response <- response_age[train.sample]
  test.data <- for_further_work[test.sample, ]
  test.response <- response_age[test.sample]
  
  # calculating RMSE for every part and default random forest
  return(wrapper_function(train.data, train.response, test.data, test.response, 100, replace=replace, sampsize=nsamp, ntree=ntree, nodesize=nodesize, mtry=nmtry))
})

print(cross.results_with_params)
print(rowMeans(cross.results_with_params))
```

По-моему, мало что поменялось?